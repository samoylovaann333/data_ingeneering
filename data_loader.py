import pandas as pd
import wget
import os
import numpy as np

class DataLoader:
    def __init__(self):
        self.FILE_ID = "1aUvCzNoEHzLiKqYh9t9MZ-8wU-qtNFNS"
        self.data_folder = "data"
        self.file_path = os.path.join(self.data_folder, "dataset.csv")
        self.df = None
    
    def download_and_load_data(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å Google Drive"""
        file_url = f"https://drive.google.com/uc?id={self.FILE_ID}"
        
        os.makedirs(self.data_folder, exist_ok=True)
        
        print("üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å Google Drive...")
        wget.download(file_url, self.file_path)
        print("\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–∫–∞—á–∞–Ω—ã!")
        
        self.df = pd.read_csv(self.file_path, encoding='latin1')
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {self.df.shape}")
        return self.df
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if os.path.exists(self.file_path):
            print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
            self.df = pd.read_csv(self.file_path, encoding='latin1')
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {self.df.shape}")
        else:
            print("üì• –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–∫–∞—á–∏–≤–∞–µ–º —Å Google Drive...")
            self.download_and_load_data()
        
        return self.df
    
    def analyze_data(self):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π"""
        if self.df is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ!")
        
        print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•:")
        print("=" * 50)
        
        analysis_results = {}
        
        for col in self.df.columns:
            col_data = self.df[col]
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            total_count = len(col_data)
            null_count = col_data.isna().sum()
            unique_count = col_data.nunique()
            
            # –ü—Ä–æ–±—É–µ–º —á–∏—Å–ª–æ–≤—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
            numeric_values = pd.to_numeric(col_data, errors='coerce')
            numeric_count = numeric_values.notna().sum()
            nan_count = numeric_values.isna().sum()
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö
            if numeric_count == total_count:  # –í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã–µ
                data_type = "numeric_all"
                if (numeric_values % 1 == 0).all():
                    subtype = "integer"
                else:
                    subtype = "float"
            elif numeric_count > 0 and numeric_count < total_count:  # –°–º–µ—à–∞–Ω–Ω—ã–µ
                data_type = "numeric_mixed"
                subtype = "mixed"
            else:  # –¢–µ–∫—Å—Ç–æ–≤—ã–µ
                data_type = "text"
                if unique_count / total_count < 0.3:
                    subtype = "low_cardinality"
                else:
                    subtype = "high_cardinality"
            
            analysis_results[col] = {
                'total_count': total_count,
                'null_count': null_count,
                'unique_count': unique_count,
                'numeric_count': numeric_count,
                'nan_count': nan_count,
                'data_type': data_type,
                'subtype': subtype,
                'sample_values': col_data.head(3).tolist()
            }
            
            # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–æ–Ω–∫–µ
            print(f"\nüìã {col}:")
            print(f"   –¢–∏–ø: {data_type} ({subtype})")
            print(f"   Null: {null_count}/{total_count} ({null_count/total_count*100:.1f}%)")
            print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {unique_count} ({unique_count/total_count*100:.1f}%)")
            if numeric_count > 0:
                print(f"   –ß–∏—Å–ª–æ–≤—ã—Ö: {numeric_count} ({numeric_count/total_count*100:.1f}%)")
            print(f"   –ü—Ä–∏–º–µ—Ä: {col_data.head(3).tolist()}")
        
        return analysis_results
    
    def convert_data_types_smart(self):
        """–£–º–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        if self.df is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ!")
        
        print("\nüîß –£–ú–ù–û–ï –ü–†–ò–í–ï–î–ï–ù–ò–ï –¢–ò–ü–û–í –î–ê–ù–ù–´–•:")
        print("=" * 50)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        analysis = self.analyze_data()
        
        memory_before = self.df.memory_usage(deep=True).sum() / 1024**2
        print(f"\nüíæ –ü–∞–º—è—Ç—å –¥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {memory_before:.2f} MB")
        
        df_optimized = self.df.copy()
        
        for col, info in analysis.items():
            try:
                data_type = info['data_type']
                subtype = info['subtype']
                null_count = info['null_count']
                
                if data_type == "numeric_all":
                    # –í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã–µ
                    numeric_values = pd.to_numeric(df_optimized[col], errors='coerce')
                    
                    if subtype == "integer":
                        # –¶–µ–ª—ã–µ —á–∏—Å–ª–∞ - –º–æ–∂–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
                        min_val = numeric_values.min()
                        max_val = numeric_values.max()
                        
                        if min_val >= 0:
                            if max_val <= 255:
                                df_optimized[col] = numeric_values.astype('uint8')
                                print(f"üî¢ {col} -> uint8 (—Ü–µ–ª—ã–µ, 0-255)")
                            elif max_val <= 65535:
                                df_optimized[col] = numeric_values.astype('uint16')
                                print(f"üî¢ {col} -> uint16 (—Ü–µ–ª—ã–µ, 0-65535)")
                            else:
                                df_optimized[col] = numeric_values.astype('uint32')
                                print(f"üî¢ {col} -> uint32 (—Ü–µ–ª—ã–µ, >65535)")
                        else:
                            df_optimized[col] = numeric_values.astype('int32')
                            print(f"üî¢ {col} -> int32 (—Ü–µ–ª—ã–µ —Å–æ –∑–Ω–∞–∫–æ–º)")
                    else:
                        # –î—Ä–æ–±–Ω—ã–µ —á–∏—Å–ª–∞
                        df_optimized[col] = numeric_values.astype('float32')
                        print(f"üî¢ {col} -> float32 (–¥—Ä–æ–±–Ω—ã–µ)")
                
                elif data_type == "numeric_mixed":
                    # –°–º–µ—à–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º float –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    numeric_values = pd.to_numeric(df_optimized[col], errors='coerce')
                    df_optimized[col] = numeric_values.astype('float32')
                    print(f"üî¢ {col} -> float32 (—Å–º–µ—à–∞–Ω–Ω—ã–µ, {info['nan_count']} NaN)")
                
                else:  # text
                    # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                    if subtype == "low_cardinality":
                        df_optimized[col] = df_optimized[col].astype('category')
                        print(f"üè∑Ô∏è  {col} -> category ({info['unique_count']} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö)")
                    else:
                        df_optimized[col] = df_optimized[col].astype('string')
                        print(f"üìù {col} -> string")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ {col}: {e}")
                continue
        
        self.df = df_optimized
        
        memory_after = self.df.memory_usage(deep=True).sum() / 1024**2
        memory_saved = memory_before - memory_after
        
        print(f"\nüíæ –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {memory_after:.2f} MB")
        print(f"üíæ –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: {memory_saved:.2f} MB ({memory_saved/memory_before*100:.1f}%)")
        
        print("‚úÖ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–≤–µ–¥–µ–Ω—ã!")
        return self.df

    def convert_data_types(self):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        return self.convert_data_types_smart()
    
    def save_data(self, file_path=None, format='parquet'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è!")
        
        if file_path is None:
            file_path = os.path.join(self.data_folder, f"optimized_dataset.{format}")
        
        os.makedirs(os.path.dirname(file_path) if os.path.dirname(file_path) else '.', exist_ok=True)
        
        if format.lower() == 'parquet':
            self.df.to_parquet(file_path, index=False)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ Parquet: {file_path}")
        elif format.lower() == 'csv':
            self.df.to_csv(file_path, index=False)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ CSV: {file_path}")
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")
        
        return file_path

    def show_info(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is not None:
            print(f"\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:")
            print(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {self.df.shape}")
            print(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
            for col, dtype in self.df.dtypes.items():
                null_count = self.df[col].isna().sum()
                unique_count = self.df[col].nunique()
                print(f"  - {col}: {dtype} (nulls: {null_count}, uniques: {unique_count})")